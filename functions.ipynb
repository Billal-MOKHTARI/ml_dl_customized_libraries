{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGWMAnWNY33ywk7yrnY5/Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Billal-MOKHTARI/ml_dl_customized_libraries/blob/main/functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "AmR1Sv5v1Fbf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import packages"
      ],
      "metadata": {
        "id": "aKdeb-r71CVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab import drive, files\n",
        "import zipfile\n",
        "import json\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,f1_score"
      ],
      "metadata": {
        "id": "9l63rZow_8Jj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mount to drive"
      ],
      "metadata": {
        "id": "a5swc4jl-16D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_access_token"
      ],
      "metadata": {
        "id": "0KCExcuBOD_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLHpN1k94mv9"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/gdrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### set kaggle environment"
      ],
      "metadata": {
        "id": "B0HQr9sM0-BI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_kaggle():\n",
        "  !pip install -q kaggle\n",
        "  files.upload()\n",
        "  !mkdir ~/.kaggle\n",
        "  !cp kaggle.json ~/.kaggle/\n",
        "  !chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "6NJv6sH2EsUI"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_kaggle_dataset(dataset_name, path):\n",
        "    \"\"\"\n",
        "    Downloads a Kaggle competition dataset and unzips it to a specified path.\n",
        "    \n",
        "    Args:\n",
        "    - dataset_name (str): the name of the Kaggle dataset (this is the name that appears in the URL)\n",
        "    - path (str): the path to which the dataset should be downloaded and unzipped\n",
        "    \n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    \n",
        "    # Set up the API credentials to download the dataset\n",
        "    # You can find your API credentials by going to your Kaggle account page and clicking \"Create New API Token\"\n",
        "    with open(\"kaggle.json\", \"r\") as f:\n",
        "            config = json.load(f)\n",
        "            kaggle_username = config[\"username\"]\n",
        "            kaggle_key = config[\"key\"]\n",
        "    \n",
        "\n",
        "    # kaggle_username = \"billalmokhtari\"\n",
        "    # kaggle_key = \"48aab974a2bbf5f3c3acc3992aea7c92\"\n",
        "    os.environ[\"KAGGLE_USERNAME\"] = kaggle_username\n",
        "    os.environ[\"KAGGLE_KEY\"] = kaggle_key\n",
        "    \n",
        "    # Make a directory for the dataset\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "        \n",
        "    # Download the dataset\n",
        "    !kaggle competitions download -c {dataset_name} -p {path}\n",
        "    \n",
        "    # Unzip the dataset\n",
        "    zip_file = os.path.join(path, f\"{dataset_name}.zip\")\n",
        "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "        zip_ref.extractall(path)\n",
        "    \n",
        "    # Delete the zip file\n",
        "    os.remove(zip_file)\n"
      ],
      "metadata": {
        "id": "zf6WKlyXEKmg"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_kaggle_dataset(\"rsna-2022-cervical-spine-fracture-detection\", \"/content/data\")"
      ],
      "metadata": {
        "id": "tJ-DPEOkGaUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models"
      ],
      "metadata": {
        "id": "1vsnnbkJ1JdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Time series"
      ],
      "metadata": {
        "id": "_6HgyTpk1qzx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prophete"
      ],
      "metadata": {
        "id": "Dh9c3qVH1tVZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prophet is forecasting procedure implemented in R and Python developped by facebook.\n",
        "\n",
        "Set up ```Prophete``` environment"
      ],
      "metadata": {
        "id": "fVq7U1oC2KqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install prophet \n",
        "from prophet import Prophet"
      ],
      "metadata": {
        "id": "vLACYTvsBBDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function with which our data will be trained"
      ],
      "metadata": {
        "id": "Mgi5q2vd2lsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training\n",
        "\"\"\"\n",
        "df should have the following format [y, ds]\n",
        "y : values\n",
        "ds : time\n",
        "\"\"\"\n",
        "def time_series_train(df, growth='linear',\n",
        "                          changepoints=None,\n",
        "                          n_changepoints=25,\n",
        "                          changepoint_range=0.8,\n",
        "                          yearly_seasonality='auto',\n",
        "                          weekly_seasonality='auto',\n",
        "                          daily_seasonality='auto',\n",
        "                          holidays=None,\n",
        "                          seasonality_mode='additive',\n",
        "                          seasonality_prior_scale=10.0,\n",
        "                          holidays_prior_scale=10.0,\n",
        "                          changepoint_prior_scale=0.05,\n",
        "                          mcmc_samples=0,\n",
        "                          interval_width=0.80,\n",
        "                          uncertainty_samples=1000,\n",
        "                          stan_backend=None):\n",
        "  m = Prophet(growth,\n",
        "              changepoints,\n",
        "              n_changepoints,\n",
        "              changepoint_range,\n",
        "              yearly_seasonality,\n",
        "              weekly_seasonality,\n",
        "              daily_seasonality,\n",
        "              holidays,\n",
        "              seasonality_mode,\n",
        "              seasonality_prior_scale,\n",
        "              holidays_prior_scale,\n",
        "              changepoint_prior_scale,\n",
        "              mcmc_samples,\n",
        "              interval_width,\n",
        "              uncertainty_samples,\n",
        "              stan_backend)\n",
        "  \n",
        "  model = m.fit(df)\n",
        "\n",
        "  return m"
      ],
      "metadata": {
        "id": "qsfZI7NR2kLn"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making predictions\n",
        "\"\"\"\n",
        "m -> Prophet\n",
        "plot -> boolean : that tells us if we'll plot tha forecasting graphic\n",
        "plot_components -> boolean : that tells us if we'll plot each component graphic\n",
        "periods -> integer : the number of the days we'll predict\n",
        "freq -> char : forecast following Days, Months, Years, Hours, .... When we set periods to 100 with freq='M', that means we\n",
        "wanna predict 100 months\n",
        "\"\"\"\n",
        "\n",
        "def time_series_predict(m, plot=True, plot_components=True, periods=100, freq='D', include_history=True):\n",
        "  future = m.make_future_dataframe(periods=periods, freq=freq, include_history=include_history)\n",
        "  forecast = m.predict(future)\n",
        "  \n",
        "  if plot :\n",
        "    plot = m.plot(forecast)\n",
        "  \n",
        "  if plot_components :\n",
        "    plot_decompose = m.plot_components(forecast)\n",
        "\n",
        "  return forecast"
      ],
      "metadata": {
        "id": "JAaW2JF82vSX"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NLP"
      ],
      "metadata": {
        "id": "2qDYaamX89Di"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question answering\n",
        "[Annotation Tool](https://haystack.deepset.ai/docs/latest/annotationmd)"
      ],
      "metadata": {
        "id": "VQx5XPOJ8_q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_up_haystack():\n",
        "  # Make sure you have a GPU running\n",
        "  !nvidia-smi\n",
        "  # Install the latest release of Haystack in your own environment\n",
        "  #! pip install farm-haystack\n",
        "\n",
        "  # Install the latest master of Haystack\n",
        "  !pip install --upgrade pip\n",
        "  !pip install git+https://github.com/deepset-ai/haystack.git#egg=farm-haystack[colab]"
      ],
      "metadata": {
        "id": "3ZMFzm4o88Pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import model\n",
        "Have a look on the different models [here](https://huggingface.co)"
      ],
      "metadata": {
        "id": "sY0pjCGpK-qa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.nodes import FARMReader\n",
        "from haystack import Pipeline, Document\n",
        "from haystack.utils import print_answers"
      ],
      "metadata": {
        "id": "8K0t_t5YK7DL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_data(train_path, save_path_drive, nb_epochs=1, save_dir_model=\"my_model\", model=\"distilbert-base-uncased-distilled-squad\", use_gpu=True):\n",
        "  reader = FARMReader(model_name_or_path=model, use_gpu=use_gpu)\n",
        "  reader.train(data_dir=data_dir, train_filename=train_path, use_gpu=use_gpu, n_epochs=n_epochs, save_dir=save_dir)\n",
        "  os.system(f\"cp -R {save_dir_model} {save_path_drive}\")\n",
        "\n",
        "  return reader\n"
      ],
      "metadata": {
        "id": "NNkFZBWUMxrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_results(reader, data_path, file_path):\n",
        "  return reader.eval_on_file(data_path, file_path, device=\"cuda\")\n"
      ],
      "metadata": {
        "id": "tfBDeXSpPmGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(reader, context, question, with_pipeline=True)\n",
        "  if not with_pipeline :\n",
        "    return reader.predict_on_texts(question,[context])\n",
        "  else:\n",
        "    p = Pipeline()\n",
        "    p.add_node(component=new_reader, name=\"Reader\", inputs=[\"Query\"])\n",
        "    res = p.run(\n",
        "      query=question documents=[Document(content=context)]\n",
        "    )\n",
        "    print_answers(res, details=\"medium\")\n",
        "\n",
        "    return res\n"
      ],
      "metadata": {
        "id": "zt2YqaNZRSq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_reader(model_path, save_path\"):\n",
        "  # If you want to load it at a later point, just do:\n",
        "  return FARMReader(model_name_or_path=model_path)"
      ],
      "metadata": {
        "id": "JC3CD8U_NsAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sentiment Analysis"
      ],
      "metadata": {
        "id": "nXqaQGWGdiOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install simpletransformers\n",
        "from simpletransformers.classification import ClassificationModel, ClassificationArgs"
      ],
      "metadata": {
        "id": "6ONYThiddlVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This creates a ClassificationModel that can be used for training, evaluating, and predicting on Binary classification tasks. The first parameter is the model_type, the second is the model_name, and the third is the number of labels in the data.\n",
        "\n",
        "model_type may be one of `['bert', 'xlnet', 'xlm', 'roberta', 'distilbert']`."
      ],
      "metadata": {
        "id": "kx6d412CfSQZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The format of the data should be \n",
        "\n",
        "```\n",
        "review, sentiment\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Jmxl5f8BhlPR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the model"
      ],
      "metadata": {
        "id": "-sYNwPJZlTRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nlp_classifier(num_labels, num_train_epochs=2, learning_rate=1e-4, model_type=\"bert\", model_name=\"bert-base-cased\"):\n",
        "  model_args = ClassificationArgs()\n",
        "  model_args.num_train_epochs = num_train_epochs\n",
        "  model_args.learning_rate = learning_rate\n",
        "\n",
        "  # create model\n",
        "  model = ClassificationModel(model_type, model_name, num_labels = num_labels, args=model_args)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "rlc1KADZeSGw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train it"
      ],
      "metadata": {
        "id": "G9B7ADo6lOFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.train_model(train_df, acc=accuracy_score)"
      ],
      "metadata": {
        "id": "UKgQ8BNtgTKR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate it"
      ],
      "metadata": {
        "id": "2--E1PdSlQa9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result, model_outputs, wrong_predictions = model.eval_model(eval_df, acc=accuracy_score)"
      ],
      "metadata": {
        "id": "umB0ts1Vg3rk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make predictions"
      ],
      "metadata": {
        "id": "m73jpG1AlZpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds, model_ouputs = model.predict(input)"
      ],
      "metadata": {
        "id": "Fc3yBMpLhQcG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Text generation"
      ],
      "metadata": {
        "id": "7aMN32iQs9Dh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install simpletransformers"
      ],
      "metadata": {
        "id": "aE8POxIVs_ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "J9zgAF2ctJqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from simpletransformers.language_modeling import LanguageModelingModel,LanguageModelingArgs"
      ],
      "metadata": {
        "id": "uBmeM-7EtM7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nlp_generation(model_type=\"gpt2\", model_name=\"gpt2\", train_batch_size=8, num_train_epochs=2, vocab_size=50257):\n",
        "  # Editing Configurations\n",
        "  model_args = LanguageModelingArgs()\n",
        "  model_args.reprocess_input_data = True\n",
        "  model_args.overwrite_output_dir = True\n",
        "  model_args.num_train_epochs = num_train_epochs\n",
        "  model_args.best_model_dir = \"outputs/best_model\"\n",
        "  model_args.save_best_model =True\n",
        "  model_args.train_batch_size = train_batch_size\n",
        "  model_args.dataset_type = \"simple\"\n",
        "  model_args.mlm = False  # mlm must be False for CLM\n",
        "  model_args.vocab_size = vocab_size\n",
        "\n",
        "  model = LanguageModelingModel(\n",
        "    model_type, model_name, args=model_args, train_files=train_file\n",
        "  )"
      ],
      "metadata": {
        "id": "5CRdDzXNtPrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resources\n",
        "[Hugging Face](https://huggingface.co/)\n",
        "\n",
        "[Haystack Annotation Tool](https://annotate.deepset.ai/)\n",
        "\n",
        "Youtube Channel: [karndeepsingh](https://www.youtube.com/@karndeepsingh)\n",
        "\n",
        "[Simple Transformers](https://simpletransformers.ai/docs/usage/)"
      ],
      "metadata": {
        "id": "X_mi15VjS9QQ"
      }
    }
  ]
}